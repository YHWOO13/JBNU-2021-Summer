{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fc184e-58af-4231-86bb-810d541cd5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n Author: Yoonhyuck WOO / JBNU_Industrial Information system Engineering\\n Date; 10. 11. 2021 - 11. 13. 2021\\n Title: Artificial Intelligence_Project 2\\n Professor: Seung-Hoon Na\\n Reference: https://cpm0722.github.io/pytorch-implementation/transformer\\n            https://pytorch.org/tutorials/beginner/transformer_tutorial.html'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    " Author: Yoonhyuck WOO / JBNU_Industrial Information system Engineering\n",
    " Date; 10. 11. 2021 - 11. 13. 2021\n",
    " Title: Artificial Intelligence_Project 2\n",
    " Professor: Seung-Hoon Na\n",
    " Reference: https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d779ec46-f5d8-49fe-89e8-cfdee2f42d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Arabic.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Chinese.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Czech.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Dutch.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\English.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\French.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\German.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Greek.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Irish.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Italian.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Japanese.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Korean.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Polish.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Portuguese.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Russian.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Scottish.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Spanish.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Vietnamese.txt']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division # 'from __future__ ': work python2.x code like python 3.x\n",
    "\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def findFiles(path):\n",
    "    return glob.glob(path) # glob.glob: Return a possibly-empty list of path names that match pathname, which must be a string containing a path specification\n",
    "\n",
    "print(findFiles(r\"C:\\Users\\LG\\Desktop\\JBNU_ISE\\GITHUB\\JBNU-2021-Summer\\Pytorch tutorial\\Text\\data\\data\\names\\*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cf166c6-65a5-4390-b396-c91099ed2f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_letters: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,;''\n",
      "n_letters: 57\n"
     ]
    }
   ],
   "source": [
    "import unicodedata # provides access to the Unicode Character Database (UCD) which defines character properties for all Unicode characters\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \".,;''\" # string.ascii: The concatenation of the 'ascii_lowercase' and 'ascii_uppercase' constants described below. This value is not locale-dependent.\n",
    "n_letters = len(all_letters)\n",
    "print('all_letters:', all_letters)\n",
    "print('n_letters:', n_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dfac26-024b-4da5-8203-41a188848010",
   "metadata": {},
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c48a13a3-0d3b-43fb-914a-6cc8961a7a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "def unicodeToAscii(s):\n",
    "# join: ['a', 'b', 'c'] -> 'abc'\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s) # unicodedata.normalize: Return the normal form form for the Unicode string unistr. Valid values for form are ‘NFC’, ‘NFKC’, ‘NFD’, and ‘NFKD’.\n",
    "        if unicodedata.category(c) != 'Mn' # Returns the general category assigned to the character chr as string.\n",
    "        and c in all_letters)\n",
    "print(unicodeToAscii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe633af-8b3b-46d6-aa4f-9a599442f0f3",
   "metadata": {},
   "source": [
    "# Build the category_lines dictionary, a list of names per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b0c14a9-a3fe-46df-ba39-23e73b6218dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abandonato', 'Abatangelo', 'Abatantuono']\n",
      "['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n"
     ]
    }
   ],
   "source": [
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding = 'utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles(r\"C:\\Users\\LG\\Desktop\\JBNU_ISE\\GITHUB\\JBNU-2021-Summer\\Pytorch tutorial\\Text\\data\\data\\names\\*.txt\"):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0] # os.path.basename: Return the base name of pathname path\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "    \n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print(category_lines['Italian'][:3])\n",
    "print(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35daf9-368e-49d5-adc1-e48640897256",
   "metadata": {},
   "source": [
    "# Turning Names into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f1d877e1-9d0b-4c8e-a249-55123b768155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 35\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n",
      "5\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Find letter index from all_letters ex) \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "print('J:', letterToIndex('J'))\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1 \n",
    "    return tensor\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "        \n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor(\"J\"))\n",
    "print(lineToTensor('Jones').size())\n",
    "print(lineToTensor('Jones').size()[0])\n",
    "print(lineToTensor('Jones'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7057c20c-b9fb-4f5c-96d3-29fcf4768f6b",
   "metadata": {},
   "source": [
    "# Creating the Network\n",
    "- Before autograd, creating a recurrent neural network in Torch involved cloning the parameters of a layer over several timesteps\n",
    "- RNN module: just 2 linear layers which operate on an input and hidden state, with a LogSoftmax layer after the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "289164eb-2cd1-4989-9974-276fb08b448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8976, -2.8895, -2.8750, -2.8039, -2.8683, -2.7978, -2.9871, -2.8966,\n",
      "         -2.8247, -2.9102, -2.8725, -2.9762, -2.9450, -2.8855, -2.8571, -2.8568,\n",
      "         -2.9636, -2.9456]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "\n",
    "'''\n",
    "input = letterToTensor('A')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)\n",
    "'''\n",
    "\n",
    "# For the sake of efficiency we don’t want to be creating a new Tensor for every step, so we will use lineToTensor instead of letterToTensor and use slices. \n",
    "#This could be further optimized by pre-computing batches of Tensors.\n",
    "input = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3051bd-7cc0-42a8-8e5e-60da55d77bb5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12704d-e2b3-4c26-88d5-52a430a95f4c",
   "metadata": {},
   "source": [
    "# MAKE helper functions \n",
    "- to interpret the output of the network, which we know to be a likelihood of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c21e3da-a8b1-474b-ab33-c7a48283e2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('French', 5)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1) #Tensor.topk:  to get the index of the greatest value\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ae7d6-556a-4f9c-9443-11078e8ed1dd",
   "metadata": {},
   "source": [
    "# A quick way to get a training example (a name and its language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "997d54ff-97c5-46a4-bd94-e1d158d09421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = Japanese /line = Okui\n",
      "category = Dutch /line = Sneijders\n",
      "category = Dutch /line = Sniders\n",
      "category = Irish /line = Sheehy\n",
      "category = Russian /line = Grizodubov\n",
      "category = Chinese /line = Hong\n",
      "category = Dutch /line = Houte\n",
      "category = French /line = Severin\n",
      "category = Chinese /line = Xiao\n",
      "category = English /line = Blackwell\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l)-1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype = torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/line =',line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1159fe0f-5a41-44a9-9a23-b0c8f217f179",
   "metadata": {},
   "source": [
    "# Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0efe2009-78f0-4bd5-af2b-65a8ccb676e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f70c9bf-5fce-48f8-a6b6-4a28913896c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Each loop of training will:\n",
    "\n",
    " Create input and target tensors\n",
    " Create a zeroed initial hidden state\n",
    " Read each letter in and\n",
    "    Keep hidden state for next letter\n",
    " Compare final output to target\n",
    " Back-propagate\n",
    " Return the output and loss\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a9a6142-6768-499c-bd37-5f70e14ec6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005 # you need to pick moderate one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e1f25e7-14e9-4a05-9d01-3241bddd0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720ff87-9240-4cb5-8920-6fdb545c07a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d39d3-deea-46f3-9855-b1caafaef295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e4cc8-fc75-4762-98d8-ed0ba9088aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a9eab-85ae-4389-8cf9-43c5eeb7e3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
