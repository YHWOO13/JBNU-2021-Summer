{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fc184e-58af-4231-86bb-810d541cd5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n Author: Yoonhyuck WOO / JBNU_Industrial Information system Engineering\\n Date; 10. 11. 2021 - 11. 13. 2021\\n Title: Artificial Intelligence_Project 2\\n Professor: Seung-Hoon Na\\n Reference: https://cpm0722.github.io/pytorch-implementation/transformer\\n            https://pytorch.org/tutorials/beginner/transformer_tutorial.html'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    " Author: Yoonhyuck WOO / JBNU_Industrial Information system Engineering\n",
    " Date; 10. 11. 2021 - 11. 13. 2021\n",
    " Title: Artificial Intelligence_Project 2\n",
    " Professor: Seung-Hoon Na\n",
    " Reference: https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d779ec46-f5d8-49fe-89e8-cfdee2f42d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Arabic.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Chinese.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Czech.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Dutch.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\English.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\French.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\German.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Greek.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Irish.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Italian.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Japanese.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Korean.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Polish.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Portuguese.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Russian.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Scottish.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Spanish.txt', 'C:\\\\Users\\\\LG\\\\Desktop\\\\JBNU_ISE\\\\GITHUB\\\\JBNU-2021-Summer\\\\Pytorch tutorial\\\\Text\\\\data\\\\data\\\\names\\\\Vietnamese.txt']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division # 'from __future__ ': work python2.x code like python 3.x\n",
    "\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def findFiles(path):\n",
    "    return glob.glob(path) # glob.glob: Return a possibly-empty list of path names that match pathname, which must be a string containing a path specification\n",
    "\n",
    "print(findFiles(r\"C:\\Users\\LG\\Desktop\\JBNU_ISE\\GITHUB\\JBNU-2021-Summer\\Pytorch tutorial\\Text\\data\\data\\names\\*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cf166c6-65a5-4390-b396-c91099ed2f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_letters: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,;''\n",
      "n_letters: 57\n"
     ]
    }
   ],
   "source": [
    "import unicodedata # provides access to the Unicode Character Database (UCD) which defines character properties for all Unicode characters\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \".,;''\" # string.ascii: The concatenation of the 'ascii_lowercase' and 'ascii_uppercase' constants described below. This value is not locale-dependent.\n",
    "n_letters = len(all_letters)\n",
    "print('all_letters:', all_letters)\n",
    "print('n_letters:', n_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dfac26-024b-4da5-8203-41a188848010",
   "metadata": {},
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c48a13a3-0d3b-43fb-914a-6cc8961a7a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "def unicodeToAscii(s):\n",
    "# join: ['a', 'b', 'c'] -> 'abc'\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s) # unicodedata.normalize: Return the normal form form for the Unicode string unistr. Valid values for form are ‘NFC’, ‘NFKC’, ‘NFD’, and ‘NFKD’.\n",
    "        if unicodedata.category(c) != 'Mn' # Returns the general category assigned to the character chr as string.\n",
    "        and c in all_letters)\n",
    "print(unicodeToAscii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe633af-8b3b-46d6-aa4f-9a599442f0f3",
   "metadata": {},
   "source": [
    "# Build the category_lines dictionary, a list of names per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b0c14a9-a3fe-46df-ba39-23e73b6218dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abandonato', 'Abatangelo', 'Abatantuono']\n",
      "['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n"
     ]
    }
   ],
   "source": [
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding = 'utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles(r\"C:\\Users\\LG\\Desktop\\JBNU_ISE\\GITHUB\\JBNU-2021-Summer\\Pytorch tutorial\\Text\\data\\data\\names\\*.txt\"):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0] # os.path.basename: Return the base name of pathname path\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "    \n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print(category_lines['Italian'][:3])\n",
    "print(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35daf9-368e-49d5-adc1-e48640897256",
   "metadata": {},
   "source": [
    "# Turning Names into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f1d877e1-9d0b-4c8e-a249-55123b768155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 35\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n",
      "5\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Find letter index from all_letters ex) \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "print('J:', letterToIndex('J'))\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1 \n",
    "    return tensor\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "        \n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor(\"J\"))\n",
    "print(lineToTensor('Jones').size())\n",
    "print(lineToTensor('Jones').size()[0])\n",
    "print(lineToTensor('Jones'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7057c20c-b9fb-4f5c-96d3-29fcf4768f6b",
   "metadata": {},
   "source": [
    "# Creating the Network\n",
    "- Before autograd, creating a recurrent neural network in Torch involved cloning the parameters of a layer over several timesteps\n",
    "- RNN module: just 2 linear layers which operate on an input and hidden state, with a LogSoftmax layer after the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "289164eb-2cd1-4989-9974-276fb08b448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8976, -2.8895, -2.8750, -2.8039, -2.8683, -2.7978, -2.9871, -2.8966,\n",
      "         -2.8247, -2.9102, -2.8725, -2.9762, -2.9450, -2.8855, -2.8571, -2.8568,\n",
      "         -2.9636, -2.9456]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "\n",
    "'''\n",
    "input = letterToTensor('A')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)\n",
    "'''\n",
    "\n",
    "# For the sake of efficiency we don’t want to be creating a new Tensor for every step, so we will use lineToTensor instead of letterToTensor and use slices. \n",
    "#This could be further optimized by pre-computing batches of Tensors.\n",
    "input = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3051bd-7cc0-42a8-8e5e-60da55d77bb5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12704d-e2b3-4c26-88d5-52a430a95f4c",
   "metadata": {},
   "source": [
    "# MAKE helper functions \n",
    "- to interpret the output of the network, which we know to be a likelihood of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c21e3da-a8b1-474b-ab33-c7a48283e2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('French', 5)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1) #Tensor.topk:  to get the index of the greatest value\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ae7d6-556a-4f9c-9443-11078e8ed1dd",
   "metadata": {},
   "source": [
    "# A quick way to get a training example (a name and its language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "997d54ff-97c5-46a4-bd94-e1d158d09421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = Japanese /line = Okui\n",
      "category = Dutch /line = Sneijders\n",
      "category = Dutch /line = Sniders\n",
      "category = Irish /line = Sheehy\n",
      "category = Russian /line = Grizodubov\n",
      "category = Chinese /line = Hong\n",
      "category = Dutch /line = Houte\n",
      "category = French /line = Severin\n",
      "category = Chinese /line = Xiao\n",
      "category = English /line = Blackwell\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l)-1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype = torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/line =',line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1159fe0f-5a41-44a9-9a23-b0c8f217f179",
   "metadata": {},
   "source": [
    "# Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0efe2009-78f0-4bd5-af2b-65a8ccb676e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f70c9bf-5fce-48f8-a6b6-4a28913896c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Each loop of training will:\n",
    "\n",
    " Create input and target tensors\n",
    " Create a zeroed initial hidden state\n",
    " Read each letter in and\n",
    "    Keep hidden state for next letter\n",
    " Compare final output to target\n",
    " Back-propagate\n",
    " Return the output and loss\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a9a6142-6768-499c-bd37-5f70e14ec6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005 # you need to pick moderate one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e1f25e7-14e9-4a05-9d01-3241bddd0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        '''\n",
    "        a = torch.tensor([[1,1],[1,1]])\n",
    "        b = torch.tensor(2)\n",
    "        c = torch.tensor(3)\n",
    "        a.add_(b,c)\n",
    "        print(a)\n",
    "        -> tensor([[7, 7],\n",
    "                  [7, 7]])\n",
    "        '''\n",
    "        return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5720ff87-9240-4cb5-8920-6fdb545c07a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i2h.weight', Parameter containing:\n",
      "tensor([[ 0.0014,  0.0304,  0.0462,  ..., -0.0487, -0.0472,  0.0013],\n",
      "        [ 0.0558, -0.0030, -0.0582,  ..., -0.0026, -0.0121, -0.0316],\n",
      "        [-0.0625,  0.0412, -0.0368,  ...,  0.0209, -0.0469, -0.0243],\n",
      "        ...,\n",
      "        [-0.0679, -0.0152,  0.0136,  ...,  0.0702, -0.0354,  0.0115],\n",
      "        [ 0.0248,  0.0729,  0.0704,  ...,  0.0715,  0.0008, -0.0466],\n",
      "        [ 0.0204,  0.0493, -0.0137,  ..., -0.0726,  0.0026,  0.0475]],\n",
      "       requires_grad=True))\n",
      "('i2h.bias', Parameter containing:\n",
      "tensor([-4.2084e-02,  7.0795e-02,  2.0870e-02, -1.7269e-02, -2.0689e-02,\n",
      "         5.8767e-02, -3.8202e-02, -5.5919e-02, -6.2633e-03,  3.7179e-02,\n",
      "        -3.0209e-02,  6.2773e-02,  2.3029e-02,  1.2049e-02, -3.5972e-02,\n",
      "         3.9118e-02, -7.2921e-04, -1.2361e-02, -3.7863e-02, -5.8283e-02,\n",
      "        -3.9429e-02, -1.0385e-02, -3.4742e-02, -3.0104e-02,  5.4405e-02,\n",
      "        -5.1978e-02, -3.9186e-02, -3.4802e-02,  1.2278e-02, -6.6084e-03,\n",
      "        -2.3152e-02, -2.0246e-02,  6.0295e-02,  7.0625e-02,  4.0169e-02,\n",
      "        -3.1638e-02,  2.2702e-02, -6.5438e-02,  4.1359e-02,  2.6394e-02,\n",
      "         1.1618e-02,  8.5499e-04,  6.6288e-02,  5.3941e-02,  2.7069e-02,\n",
      "        -7.5266e-03,  9.2901e-03,  1.3919e-02, -2.2758e-02, -1.9379e-02,\n",
      "         2.3257e-02, -5.2170e-02, -6.2941e-02, -2.0803e-02,  6.2607e-02,\n",
      "         5.8605e-02, -4.7012e-02,  5.8645e-02, -6.0689e-02, -7.6185e-03,\n",
      "        -2.5193e-02, -1.0542e-02,  1.7360e-06,  3.7969e-02,  4.0614e-02,\n",
      "        -2.4752e-02,  5.9551e-02,  2.7039e-02, -1.8639e-02, -6.2391e-02,\n",
      "         1.8123e-02, -2.9549e-02,  6.4250e-02, -3.9085e-02, -6.9873e-02,\n",
      "         4.7790e-02, -2.4890e-02, -2.9984e-02, -2.6916e-03,  2.9824e-02,\n",
      "         4.1887e-02, -3.5784e-02, -5.7974e-02,  3.0320e-02, -5.8000e-02,\n",
      "        -5.5539e-02,  7.2440e-02,  5.8361e-02, -2.1117e-02,  3.5681e-02,\n",
      "        -1.4627e-03, -3.7709e-02, -5.1691e-02, -5.3143e-02, -4.9379e-02,\n",
      "        -5.7138e-02, -2.0391e-03, -6.1471e-02,  2.7115e-02, -3.8591e-02,\n",
      "        -3.5332e-02,  2.6363e-02, -3.4836e-02,  1.9566e-02, -2.2759e-03,\n",
      "         3.2630e-02, -5.2364e-02, -4.7298e-02,  3.1214e-02,  6.1001e-02,\n",
      "        -6.5033e-03,  4.1655e-02,  2.9586e-02, -5.6292e-02,  3.7462e-02,\n",
      "        -6.4002e-02, -3.9809e-02, -1.8698e-02, -2.0501e-02, -2.9077e-02,\n",
      "         8.8397e-03,  1.9003e-02,  6.8551e-02, -5.2931e-02, -4.3690e-03,\n",
      "        -2.6669e-02, -1.8603e-02,  7.0623e-02], requires_grad=True))\n",
      "('i2o.weight', Parameter containing:\n",
      "tensor([[-0.0676, -0.0148, -0.0571,  ..., -0.0282, -0.0373,  0.0541],\n",
      "        [ 0.0731, -0.0182,  0.0263,  ...,  0.0478, -0.0122, -0.0512],\n",
      "        [ 0.0634,  0.0411,  0.0267,  ...,  0.0675,  0.0534, -0.0189],\n",
      "        ...,\n",
      "        [ 0.0078, -0.0006, -0.0560,  ..., -0.0351,  0.0023,  0.0735],\n",
      "        [-0.0116, -0.0017, -0.0067,  ..., -0.0018, -0.0299,  0.0044],\n",
      "        [ 0.0614,  0.0359, -0.0376,  ...,  0.0699, -0.0563,  0.0504]],\n",
      "       requires_grad=True))\n",
      "('i2o.bias', Parameter containing:\n",
      "tensor([-0.0637, -0.0481,  0.0112,  0.0316,  0.0568,  0.0603, -0.0596,  0.0376,\n",
      "         0.0104, -0.0580, -0.0350, -0.0542, -0.0225, -0.0104,  0.0454,  0.0091,\n",
      "        -0.0525, -0.0086], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for p in rnn.named_parameters():\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a9eab-85ae-4389-8cf9-43c5eeb7e3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
