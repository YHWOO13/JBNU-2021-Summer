{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row tensor([1., 1., 1., 1.])\n",
      "First column tensor([1., 1., 1., 1.])\n",
      "Last column tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 3., 1., 1.],\n",
      "        [1., 3., 1., 1.],\n",
      "        [1., 3., 1., 1.],\n",
      "        [1., 3., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "tensor = torch.ones(4,4)\n",
    "\n",
    "print('First row', tensor[0])\n",
    "print('First column', tensor[:, 2])\n",
    "print('Last column', tensor[..., -1])\n",
    "tensor[:,1] = 3\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(2.0, requires_grad = True)\n",
    "y = w ** 2\n",
    "z = 2*y + 5\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: None\n",
      "수식을 w로 미분한 값: 8.0\n"
     ]
    }
   ],
   "source": [
    "a = z.backward() # 그냥 수식을 w에 대해 미분\n",
    "\n",
    "print('a:',a)\n",
    "\n",
    "print('수식을 w로 미분한 값: {}'.format(w.grad)) # 미분후 w에 2값(앞에서 설정해 준) 대입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = set('you need to run'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to', 'you', 'run', 'need'}\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = 'you need to run'.count('u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[13, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "q = [1,2,3,4]\n",
    "c = copy.deepcopy(q)\n",
    "c[0] = 13\n",
    "print(q)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2,3,4],\n",
    "     [5,6,7,8]]\n",
    "a = np.array(a)\n",
    "# b = copy.deepcopy(a)\n",
    "# b[0] = 13\n",
    "# print(a)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [5 6 7]]\n",
      "[[2 3 4]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "print(a[:, :-1])\n",
    "print(a[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1633787019.6264668\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(start)\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "k = torch.zeros(3,1,7)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'want', 'to', 'be', 'a', 'ji', 'sung', 'park']\n"
     ]
    }
   ],
   "source": [
    "sent = \"I want to be a Ji sung Park\"\n",
    "a = get_tokenizer(\"basic_english\")\n",
    "token = a(\"I want to be a Ji sung Park\")\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab()\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab_from_iterator(token,specials=[\"<unk>\"])\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(map(token, {1:'a',2:'b',3:'c'}), specials=['<unk>']) \n",
    "vocab.set_default_index(vocab['<unk>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['1', '1', '1', '3', '3']\n",
    "a['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"I AM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "def yield_tokens(file_path):\n",
    "    with io.open(file_path, encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            yield line.strip().split()\n",
    "            print(line)\n",
    "vocab = build_vocab_from_iterator(yield_tokens(r\"C:\\Users\\LG\\Desktop\\JBNU_ISE\\GITHUB\\JBNU-2021-Summer\\Pytorch tutorial\\Text\\textfile.txt\"), specials=[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab(['I','want','to','be','Ji','Sung','Park'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(get_tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "text_pipeline(\"I want to be Ji Sung Park\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = yield_tokens(r\"C:\\Users\\LG\\Desktop\\JBNU_ISE\\GITHUB\\JBNU-2021-Summer\\Pytorch tutorial\\Text\\textfile.txt\")\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "train_iter2 = AG_NEWS(split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(train_iter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "#text_pipeline(\"I\")\n",
    "label_pipeline('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.randn(10,2,3)\n",
    "print(g)\n",
    "#print(torch.numel(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.size(0))\n",
    "bsz = 5\n",
    "seq_len = g.size(0) // bsz\n",
    "print('seq_len:',seq_len)\n",
    "#print(seq_len)\n",
    "g = g[:seq_len * bsz]\n",
    "#print(data)\n",
    "g = g.view(bsz, seq_len).t()#.contiguous()\n",
    "print(g)\n",
    "print(g.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.randn(10,2,3)\n",
    "print(v)\n",
    "# print('='*58)\n",
    "# print(v[:3])\n",
    "# print('='*58)\n",
    "\n",
    "\n",
    "# print('-'*33)\n",
    "# data1 = data.view(bsz, seq_len)\n",
    "# print(data1)\n",
    "\n",
    "# print('='*58)\n",
    "# data2 = data1.view(-1, seq_len).t()\n",
    "# print(data1)\n",
    "\n",
    "# print('='*58)\n",
    "# data1 = data.view(-1, seq_len).t().contiguous()\n",
    "# print(data1)\n",
    "# # v = v\n",
    "# # o = filter(lambda t: t.numel() > 0, v)\n",
    "# # p = tuple(o)\n",
    "\n",
    "# # print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7381b9c0041b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "q = torch.cat(p)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  0 i:  0\n",
      "batch:  1 i:  3\n",
      "batch:  2 i:  6\n",
      "batch:  3 i:  9\n",
      "batch:  4 i:  12\n",
      "batch:  5 i:  15\n",
      "batch:  6 i:  18\n"
     ]
    }
   ],
   "source": [
    "  for batch, i in enumerate(range(0, 22 - 1, 3)):\n",
    "        print('batch: ', batch, 'i: ',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35 # chunks of length\n",
    "def get_batch(source, i): # -> Tuple[Tensor, Tensor]\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape [full_seq_len, batch_size]\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
    "        target has shape [seq_len * batch_size]\n",
    "    \"\"\"\n",
    "    print('len(source)', len(source))\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    print('seq_len', seq_len)\n",
    "    \n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target\n",
    "\n",
    "\n",
    "get_batch(v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int):#->Tensor\n",
    "    \"\"\"\n",
    "    Generates an upper-triangular matrix of -inf, with zeros on diag.\n",
    "    triu: Generates an upper-triangular matrix\n",
    "    \"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal = 1)\n",
    "\n",
    "\n",
    "generate_square_subsequent_mask(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'add_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c91be7516a5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mxyz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqwer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxyz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'add_'"
     ]
    }
   ],
   "source": [
    "qwer = [1,2,3,4]\n",
    "xyz = [1,2,3,4]\n",
    "for p in qwer:\n",
    "    p.add_(xyz, alpha=-0.5)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
