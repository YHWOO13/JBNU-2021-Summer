{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n Author: Yoonhyuck WOO / JBNU_Industrial Information system Engineering\\n Date; 7. 20. 2021 - 7. 21. 2021\\n Title: Linear Regression\\n Reference: https://wikidocs.net/53545'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    " Author: Yoonhyuck WOO / JBNU_Industrial Information system Engineering\n",
    " Date; 7. 20. 2021 - 7. 21. 2021\n",
    " Title: Linear Regression\n",
    " Reference: https://wikidocs.net/53545'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x167a98c6670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1,2,3],[2,2,3],[3,2,3],[4,2,3],[5,2,3],[6,2,3],[7,2,3],[8,2,3],[9,2,3]])\n",
    "y_train = torch.FloatTensor([[1],[1],[1],[1],[1],[1],[1],[1],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.zeros(1, requires_grad = True)\n",
    "b1 = torch.zeros(1, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = x_train * w1 + b1\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1999 w: 0.067, b: 0.020 Cost: 1.000000\n",
      "Epoch  100/1999 w: 0.133, b: 0.417 Cost: 0.087185\n",
      "Epoch  200/1999 w: 0.082, b: 0.641 Cost: 0.033114\n",
      "Epoch  300/1999 w: 0.050, b: 0.779 Cost: 0.012577\n",
      "Epoch  400/1999 w: 0.031, b: 0.864 Cost: 0.004777\n",
      "Epoch  500/1999 w: 0.019, b: 0.916 Cost: 0.001814\n",
      "Epoch  600/1999 w: 0.012, b: 0.948 Cost: 0.000689\n",
      "Epoch  700/1999 w: 0.007, b: 0.968 Cost: 0.000262\n",
      "Epoch  800/1999 w: 0.004, b: 0.980 Cost: 0.000099\n",
      "Epoch  900/1999 w: 0.003, b: 0.988 Cost: 0.000038\n",
      "Epoch 1000/1999 w: 0.002, b: 0.993 Cost: 0.000014\n",
      "Epoch 1100/1999 w: 0.001, b: 0.995 Cost: 0.000005\n",
      "Epoch 1200/1999 w: 0.001, b: 0.997 Cost: 0.000002\n",
      "Epoch 1300/1999 w: 0.000, b: 0.998 Cost: 0.000001\n",
      "Epoch 1400/1999 w: 0.000, b: 0.999 Cost: 0.000000\n",
      "Epoch 1500/1999 w: 0.000, b: 0.999 Cost: 0.000000\n",
      "Epoch 1600/1999 w: 0.000, b: 1.000 Cost: 0.000000\n",
      "Epoch 1700/1999 w: 0.000, b: 1.000 Cost: 0.000000\n",
      "Epoch 1800/1999 w: 0.000, b: 1.000 Cost: 0.000000\n",
      "Epoch 1900/1999 w: 0.000, b: 1.000 Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD([w1,b1], lr = 0.01)\n",
    "\n",
    "nb_epochs = 1999\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    hypothesis = x_train * w1 + b1\n",
    "        \n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    optimizer.zero_grad() # 미분값을 계속 0으로 초기화\n",
    "    cost.backward() # 구한 loss로부터 back propagation을 통해 각 변수마다 loss에 대한 gradient 구해주기\n",
    "                    # starting backpropagation\n",
    "    optimizer.step() # starting gradient descent\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} w: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, w1.item(), b1.item(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = torch.zeros((3,1), requires_grad = True)\n",
    "b2 = torch.zeros(1, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]) Cost: 1.000000\n",
      "Epoch    1/20 hypothesis: tensor([0.3800, 0.4800, 0.5800, 0.6800, 0.7800, 0.8800, 0.9800, 1.0800, 1.1800]) Cost: 0.115067\n",
      "Epoch    2/20 hypothesis: tensor([0.4503, 0.5589, 0.6676, 0.7763, 0.8849, 0.9936, 1.1023, 1.2109, 1.3196]) Cost: 0.091963\n",
      "Epoch    3/20 hypothesis: tensor([0.4795, 0.5852, 0.6909, 0.7966, 0.9022, 1.0079, 1.1136, 1.2193, 1.3250]) Cost: 0.084018\n",
      "Epoch    4/20 hypothesis: tensor([0.5026, 0.6039, 0.7053, 0.8067, 0.9080, 1.0094, 1.1108, 1.2121, 1.3135]) Cost: 0.076962\n",
      "Epoch    5/20 hypothesis: tensor([0.5240, 0.6210, 0.7181, 0.8151, 0.9122, 1.0092, 1.1063, 1.2033, 1.3004]) Cost: 0.070502\n",
      "Epoch    6/20 hypothesis: tensor([0.5444, 0.6373, 0.7302, 0.8231, 0.9160, 1.0089, 1.1018, 1.1947, 1.2875]) Cost: 0.064584\n",
      "Epoch    7/20 hypothesis: tensor([0.5640, 0.6529, 0.7418, 0.8307, 0.9196, 1.0085, 1.0974, 1.1863, 1.2752]) Cost: 0.059162\n",
      "Epoch    8/20 hypothesis: tensor([0.5827, 0.6678, 0.7529, 0.8379, 0.9230, 1.0081, 1.0932, 1.1783, 1.2634]) Cost: 0.054196\n",
      "Epoch    9/20 hypothesis: tensor([0.6006, 0.6820, 0.7635, 0.8449, 0.9263, 1.0078, 1.0892, 1.1707, 1.2521]) Cost: 0.049647\n",
      "Epoch   10/20 hypothesis: tensor([0.6177, 0.6956, 0.7736, 0.8515, 0.9295, 1.0074, 1.0854, 1.1634, 1.2413]) Cost: 0.045480\n",
      "Epoch   11/20 hypothesis: tensor([0.6341, 0.7087, 0.7833, 0.8579, 0.9325, 1.0071, 1.0817, 1.1563, 1.2310]) Cost: 0.041662\n",
      "Epoch   12/20 hypothesis: tensor([0.6498, 0.7212, 0.7926, 0.8640, 0.9354, 1.0068, 1.0782, 1.1496, 1.2210]) Cost: 0.038165\n",
      "Epoch   13/20 hypothesis: tensor([0.6648, 0.7332, 0.8015, 0.8698, 0.9382, 1.0065, 1.0749, 1.1432, 1.2116]) Cost: 0.034961\n",
      "Epoch   14/20 hypothesis: tensor([0.6792, 0.7446, 0.8100, 0.8754, 0.9408, 1.0063, 1.0717, 1.1371, 1.2025]) Cost: 0.032027\n",
      "Epoch   15/20 hypothesis: tensor([0.6929, 0.7556, 0.8182, 0.8808, 0.9434, 1.0060, 1.0686, 1.1312, 1.1938]) Cost: 0.029338\n",
      "Epoch   16/20 hypothesis: tensor([0.7061, 0.7660, 0.8260, 0.8859, 0.9458, 1.0057, 1.0656, 1.1256, 1.1855]) Cost: 0.026876\n",
      "Epoch   17/20 hypothesis: tensor([0.7187, 0.7761, 0.8334, 0.8908, 0.9481, 1.0055, 1.0628, 1.1202, 1.1775]) Cost: 0.024620\n",
      "Epoch   18/20 hypothesis: tensor([0.7308, 0.7857, 0.8406, 0.8955, 0.9504, 1.0052, 1.0601, 1.1150, 1.1699]) Cost: 0.022553\n",
      "Epoch   19/20 hypothesis: tensor([0.7423, 0.7949, 0.8474, 0.8999, 0.9525, 1.0050, 1.0576, 1.1101, 1.1626]) Cost: 0.020660\n",
      "Epoch   20/20 hypothesis: tensor([0.7534, 0.8037, 0.8539, 0.9042, 0.9545, 1.0048, 1.0551, 1.1054, 1.1557]) Cost: 0.018926\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD([w2,b2], lr = 0.01)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    hypothesis = x_train.matmul(w2) + b2\n",
    "        \n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    optimizer.zero_grad() # 미분값을 계속 0으로 초기화\n",
    "    cost.backward() # 구한 loss로부터 back propagation을 통해 각 변수마다 loss에 대한 gradient 구해주기 (starting backpropagation)\n",
    "    optimizer.step() # starting gradient descent\n",
    "\n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "    epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Modeule로 구현하는 선형 회귀 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 3) #input_dim = 1, output_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Linear(input_size, output_size, bias)\n",
    "- 수동으로 self.weights 와 self.bias 를 정의하고 초기화하고 xb @ self.weights + self.bias를 계산하는 대신에 이것들을 해내는 PyTorch 클래스인 nn.Linear를 선형 계층으로 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119],\n",
      "        [ 0.2710, -0.5435,  0.3462],\n",
      "        [-0.1188,  0.2937,  0.0803]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0707,  0.1601,  0.0285], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer3 = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/33 Cost: 0.706220\n",
      "Epoch    1/33 Cost: 0.513206\n",
      "Epoch    2/33 Cost: 0.411482\n",
      "Epoch    3/33 Cost: 0.355884\n",
      "Epoch    4/33 Cost: 0.323651\n",
      "Epoch    5/33 Cost: 0.303312\n",
      "Epoch    6/33 Cost: 0.289083\n",
      "Epoch    7/33 Cost: 0.278045\n",
      "Epoch    8/33 Cost: 0.268725\n",
      "Epoch    9/33 Cost: 0.260377\n",
      "Epoch   10/33 Cost: 0.252623\n",
      "Epoch   11/33 Cost: 0.245269\n",
      "Epoch   12/33 Cost: 0.238214\n",
      "Epoch   13/33 Cost: 0.231405\n",
      "Epoch   14/33 Cost: 0.224812\n",
      "Epoch   15/33 Cost: 0.218418\n",
      "Epoch   16/33 Cost: 0.212212\n",
      "Epoch   17/33 Cost: 0.206184\n",
      "Epoch   18/33 Cost: 0.200329\n",
      "Epoch   19/33 Cost: 0.194642\n",
      "Epoch   20/33 Cost: 0.189116\n",
      "Epoch   21/33 Cost: 0.183747\n",
      "Epoch   22/33 Cost: 0.178530\n",
      "Epoch   23/33 Cost: 0.173462\n",
      "Epoch   24/33 Cost: 0.168537\n",
      "Epoch   25/33 Cost: 0.163753\n",
      "Epoch   26/33 Cost: 0.159104\n",
      "Epoch   27/33 Cost: 0.154587\n",
      "Epoch   28/33 Cost: 0.150199\n",
      "Epoch   29/33 Cost: 0.145935\n",
      "Epoch   30/33 Cost: 0.141792\n",
      "Epoch   31/33 Cost: 0.137766\n",
      "Epoch   32/33 Cost: 0.133855\n",
      "Epoch   33/33 Cost: 0.130055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syjy0\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Using a target size (torch.Size([9, 1])) that is different to the input size (torch.Size([9, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 33\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    prediction = model(x_train) # x_train. shape = 9x3\n",
    "    \n",
    "    cost = F.mse_loss(prediction, y_train) # 평균 제곱 오차 함수\n",
    "    \n",
    "    optimizer3.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer3.step()\n",
    "    \n",
    "\n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "    epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델을 클래스로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train2 = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단순한 선형 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn.Linear(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/21 Cost: 34.374695\n",
      "Epoch    1/21 Cost: 27.248152\n",
      "Epoch    2/21 Cost: 21.614624\n",
      "Epoch    3/21 Cost: 17.161257\n",
      "Epoch    4/21 Cost: 13.640744\n",
      "Epoch    5/21 Cost: 10.857602\n",
      "Epoch    6/21 Cost: 8.657315\n",
      "Epoch    7/21 Cost: 6.917747\n",
      "Epoch    8/21 Cost: 5.542353\n",
      "Epoch    9/21 Cost: 4.454821\n",
      "Epoch   10/21 Cost: 3.594830\n",
      "Epoch   11/21 Cost: 2.914701\n",
      "Epoch   12/21 Cost: 2.376743\n",
      "Epoch   13/21 Cost: 1.951166\n",
      "Epoch   14/21 Cost: 1.614423\n",
      "Epoch   15/21 Cost: 1.347898\n",
      "Epoch   16/21 Cost: 1.136881\n",
      "Epoch   17/21 Cost: 0.969739\n",
      "Epoch   18/21 Cost: 0.837281\n",
      "Epoch   19/21 Cost: 0.732241\n",
      "Epoch   20/21 Cost: 0.648874\n",
      "Epoch   21/21 Cost: 0.582641\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = torch.optim.SGD(model4.parameters(), lr = 0.01)\n",
    "nb_epochs = 21\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    prediction = model4(x_train2)\n",
    "    cost = F.mse_loss(prediction, y_train2)\n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer2.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} Cost: {:6f}'.format(\n",
    "    epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다중 선형 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = nn.Linear(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3,1)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/21 Cost: 10.285702\n",
      "Epoch    1/21 Cost: 0.307052\n",
      "Epoch    2/21 Cost: 0.128279\n",
      "Epoch    3/21 Cost: 0.114943\n",
      "Epoch    4/21 Cost: 0.105251\n",
      "Epoch    5/21 Cost: 0.096416\n",
      "Epoch    6/21 Cost: 0.088323\n",
      "Epoch    7/21 Cost: 0.080909\n",
      "Epoch    8/21 Cost: 0.074117\n",
      "Epoch    9/21 Cost: 0.067896\n",
      "Epoch   10/21 Cost: 0.062197\n",
      "Epoch   11/21 Cost: 0.056976\n",
      "Epoch   12/21 Cost: 0.052193\n",
      "Epoch   13/21 Cost: 0.047812\n",
      "Epoch   14/21 Cost: 0.043799\n",
      "Epoch   15/21 Cost: 0.040122\n",
      "Epoch   16/21 Cost: 0.036754\n",
      "Epoch   17/21 Cost: 0.033669\n",
      "Epoch   18/21 Cost: 0.030843\n",
      "Epoch   19/21 Cost: 0.028254\n",
      "Epoch   20/21 Cost: 0.025882\n",
      "Epoch   21/21 Cost: 0.023710\n"
     ]
    }
   ],
   "source": [
    "optimizer4 = torch.optim.SGD(model6.parameters(), lr = 0.01)\n",
    "nb_epochs = 21\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    prediction = model6(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    optimizer4.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer4.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} Cost: {:6f}'.format(\n",
    "    epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미니배치와 배치 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터로드: Dataset을 커스텀하여 만들 수도 있지만 여기서는 텐서를 입력받아 Dataset의 형태로 변환해주는 TensorDataset을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset # 텐서데이터셋 => 기본적으로 텐서를 입력 받는다. 텐서 형태로 데이터를 정의\n",
    "from torch.utils.data import DataLoader # 데이터로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = nn.Linear(3,1)\n",
    "optimizer5 = torch.optim.SGD(model7.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/21 Batch 1/5 Cost: 1.947129\n",
      "Epoch    0/21 Batch 2/5 Cost: 8.984169\n",
      "Epoch    0/21 Batch 3/5 Cost: 5.974807\n",
      "Epoch    0/21 Batch 4/5 Cost: 8.436694\n",
      "Epoch    0/21 Batch 5/5 Cost: 7.347460\n",
      "=================================================\n",
      "Epoch    1/21 Batch 1/5 Cost: 3.850255\n",
      "Epoch    1/21 Batch 2/5 Cost: 1.571764\n",
      "Epoch    1/21 Batch 3/5 Cost: 6.625402\n",
      "Epoch    1/21 Batch 4/5 Cost: 8.882811\n",
      "Epoch    1/21 Batch 5/5 Cost: 15.667125\n",
      "=================================================\n",
      "Epoch    2/21 Batch 1/5 Cost: 11.083865\n",
      "Epoch    2/21 Batch 2/5 Cost: 2.762223\n",
      "Epoch    2/21 Batch 3/5 Cost: 11.393532\n",
      "Epoch    2/21 Batch 4/5 Cost: 2.227818\n",
      "Epoch    2/21 Batch 5/5 Cost: 2.051529\n",
      "=================================================\n",
      "Epoch    3/21 Batch 1/5 Cost: 10.313185\n",
      "Epoch    3/21 Batch 2/5 Cost: 4.612836\n",
      "Epoch    3/21 Batch 3/5 Cost: 6.490991\n",
      "Epoch    3/21 Batch 4/5 Cost: 0.686643\n",
      "Epoch    3/21 Batch 5/5 Cost: 12.306970\n",
      "=================================================\n",
      "Epoch    4/21 Batch 1/5 Cost: 9.701584\n",
      "Epoch    4/21 Batch 2/5 Cost: 1.861492\n",
      "Epoch    4/21 Batch 3/5 Cost: 8.159747\n",
      "Epoch    4/21 Batch 4/5 Cost: 3.535717\n",
      "Epoch    4/21 Batch 5/5 Cost: 9.468681\n",
      "=================================================\n",
      "Epoch    5/21 Batch 1/5 Cost: 1.174956\n",
      "Epoch    5/21 Batch 2/5 Cost: 8.253941\n",
      "Epoch    5/21 Batch 3/5 Cost: 4.181854\n",
      "Epoch    5/21 Batch 4/5 Cost: 13.643423\n",
      "Epoch    5/21 Batch 5/5 Cost: 0.992986\n",
      "=================================================\n",
      "Epoch    6/21 Batch 1/5 Cost: 4.855903\n",
      "Epoch    6/21 Batch 2/5 Cost: 4.152285\n",
      "Epoch    6/21 Batch 3/5 Cost: 8.527368\n",
      "Epoch    6/21 Batch 4/5 Cost: 3.982041\n",
      "Epoch    6/21 Batch 5/5 Cost: 12.001098\n",
      "=================================================\n",
      "Epoch    7/21 Batch 1/5 Cost: 9.963672\n",
      "Epoch    7/21 Batch 2/5 Cost: 3.952359\n",
      "Epoch    7/21 Batch 3/5 Cost: 7.595572\n",
      "Epoch    7/21 Batch 4/5 Cost: 4.781186\n",
      "Epoch    7/21 Batch 5/5 Cost: 1.946226\n",
      "=================================================\n",
      "Epoch    8/21 Batch 1/5 Cost: 0.649054\n",
      "Epoch    8/21 Batch 2/5 Cost: 9.883905\n",
      "Epoch    8/21 Batch 3/5 Cost: 9.354149\n",
      "Epoch    8/21 Batch 4/5 Cost: 2.584064\n",
      "Epoch    8/21 Batch 5/5 Cost: 9.155259\n",
      "=================================================\n",
      "Epoch    9/21 Batch 1/5 Cost: 7.849206\n",
      "Epoch    9/21 Batch 2/5 Cost: 10.428959\n",
      "Epoch    9/21 Batch 3/5 Cost: 3.557600\n",
      "Epoch    9/21 Batch 4/5 Cost: 4.015380\n",
      "Epoch    9/21 Batch 5/5 Cost: 1.906331\n",
      "=================================================\n",
      "Epoch   10/21 Batch 1/5 Cost: 7.475123\n",
      "Epoch   10/21 Batch 2/5 Cost: 2.065754\n",
      "Epoch   10/21 Batch 3/5 Cost: 3.351194\n",
      "Epoch   10/21 Batch 4/5 Cost: 9.192033\n",
      "Epoch   10/21 Batch 5/5 Cost: 9.003385\n",
      "=================================================\n",
      "Epoch   11/21 Batch 1/5 Cost: 10.280012\n",
      "Epoch   11/21 Batch 2/5 Cost: 4.922849\n",
      "Epoch   11/21 Batch 3/5 Cost: 8.160836\n",
      "Epoch   11/21 Batch 4/5 Cost: 2.832442\n",
      "Epoch   11/21 Batch 5/5 Cost: 0.309759\n",
      "=================================================\n",
      "Epoch   12/21 Batch 1/5 Cost: 3.484324\n",
      "Epoch   12/21 Batch 2/5 Cost: 6.672561\n",
      "Epoch   12/21 Batch 3/5 Cost: 6.802260\n",
      "Epoch   12/21 Batch 4/5 Cost: 7.625825\n",
      "Epoch   12/21 Batch 5/5 Cost: 3.110918\n",
      "=================================================\n",
      "Epoch   13/21 Batch 1/5 Cost: 11.566013\n",
      "Epoch   13/21 Batch 2/5 Cost: 6.138278\n",
      "Epoch   13/21 Batch 3/5 Cost: 2.485022\n",
      "Epoch   13/21 Batch 4/5 Cost: 4.199524\n",
      "Epoch   13/21 Batch 5/5 Cost: 3.082350\n",
      "=================================================\n",
      "Epoch   14/21 Batch 1/5 Cost: 5.600531\n",
      "Epoch   14/21 Batch 2/5 Cost: 2.448821\n",
      "Epoch   14/21 Batch 3/5 Cost: 7.223374\n",
      "Epoch   14/21 Batch 4/5 Cost: 4.813351\n",
      "Epoch   14/21 Batch 5/5 Cost: 11.248146\n",
      "=================================================\n",
      "Epoch   15/21 Batch 1/5 Cost: 1.349706\n",
      "Epoch   15/21 Batch 2/5 Cost: 8.845896\n",
      "Epoch   15/21 Batch 3/5 Cost: 2.442315\n",
      "Epoch   15/21 Batch 4/5 Cost: 5.844760\n",
      "Epoch   15/21 Batch 5/5 Cost: 13.982923\n",
      "=================================================\n",
      "Epoch   16/21 Batch 1/5 Cost: 1.652019\n",
      "Epoch   16/21 Batch 2/5 Cost: 1.332086\n",
      "Epoch   16/21 Batch 3/5 Cost: 10.166463\n",
      "Epoch   16/21 Batch 4/5 Cost: 9.819427\n",
      "Epoch   16/21 Batch 5/5 Cost: 4.526261\n",
      "=================================================\n",
      "Epoch   17/21 Batch 1/5 Cost: 4.702513\n",
      "Epoch   17/21 Batch 2/5 Cost: 3.746461\n",
      "Epoch   17/21 Batch 3/5 Cost: 5.637633\n",
      "Epoch   17/21 Batch 4/5 Cost: 7.761307\n",
      "Epoch   17/21 Batch 5/5 Cost: 6.326167\n",
      "=================================================\n",
      "Epoch   18/21 Batch 1/5 Cost: 5.395684\n",
      "Epoch   18/21 Batch 2/5 Cost: 1.615337\n",
      "Epoch   18/21 Batch 3/5 Cost: 9.674688\n",
      "Epoch   18/21 Batch 4/5 Cost: 7.246482\n",
      "Epoch   18/21 Batch 5/5 Cost: 1.734511\n",
      "=================================================\n",
      "Epoch   19/21 Batch 1/5 Cost: 7.669018\n",
      "Epoch   19/21 Batch 2/5 Cost: 6.403649\n",
      "Epoch   19/21 Batch 3/5 Cost: 3.254546\n",
      "Epoch   19/21 Batch 4/5 Cost: 5.815460\n",
      "Epoch   19/21 Batch 5/5 Cost: 2.906617\n",
      "=================================================\n",
      "Epoch   20/21 Batch 1/5 Cost: 3.058444\n",
      "Epoch   20/21 Batch 2/5 Cost: 3.520344\n",
      "Epoch   20/21 Batch 3/5 Cost: 6.871985\n",
      "Epoch   20/21 Batch 4/5 Cost: 6.802556\n",
      "Epoch   20/21 Batch 5/5 Cost: 8.277581\n",
      "=================================================\n",
      "Epoch   21/21 Batch 1/5 Cost: 3.210736\n",
      "Epoch   21/21 Batch 2/5 Cost: 6.301483\n",
      "Epoch   21/21 Batch 3/5 Cost: 7.086629\n",
      "Epoch   21/21 Batch 4/5 Cost: 2.271511\n",
      "Epoch   21/21 Batch 5/5 Cost: 10.606083\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "np_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        #print(batch_idx)\n",
    "        #print(samples)\n",
    "    #print('=' * 33)\n",
    "        x_train, y_train = samples\n",
    "        prediction = model7(x_train)\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        optimizer5.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer5.step()\n",
    "        \n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost: {:6f}'.format(\n",
    "        epoch, nb_epochs, batch_idx+1, len(dataloader), cost.item()))\n",
    "    print('='*49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 커스텀 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass CustomDataset(torch.utils.data.Dataset):\\n    def __init__(self):\\n    # 데이터셋의 전처리를 해주는 부분    \\n    def __len__(self):\\n    # 데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\\n    def __getitem(self, idx):\\n    # 데이터셋에서 특정 1개의 샘플을 가져오는 함수'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "    # 데이터셋의 전처리를 해주는 부분    \n",
    "    def __len__(self):\n",
    "    # 데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
    "    def __getitem(self, idx):\n",
    "    # 데이터셋에서 특정 1개의 샘플을 가져오는 함수'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.x_data = [[1,2,3],\n",
    "                       [2,2,3],\n",
    "                       [3,2,3],\n",
    "                       [4,2,3]]\n",
    "        self.y_data = [[1],[2],[3],[4]]\n",
    "        \n",
    "        # 총 데이터의 개수 리턴\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = torch.nn.Linear(3,1)\n",
    "optimizer10 = torch.optim.SGD(model8.parameters(), lr = 1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
